/**
 * #offsets.ts
 *
 * Code generated by ts-proto. DO NOT EDIT.
 * @packageDocumentation
 */
/* eslint-disable */
import Long from "long";
import _m0 from "protobufjs/minimal.js";
import { messageTypeRegistry } from "../../../../../typeRegistry.js";
function createBaseDataSourceOffsetRange() {
    return { kafkaTopicOffsetRange: undefined };
}
export const DataSourceOffsetRange = {
    $type: "reddit.coreplatform.cloudroutines.scheduling.v1.DataSourceOffsetRange",
    encode(message, writer = _m0.Writer.create()) {
        if (message.kafkaTopicOffsetRange !== undefined) {
            DataSourceOffsetRange_KafkaTopicOffsetRange.encode(message.kafkaTopicOffsetRange, writer.uint32(10).fork())
                .ldelim();
        }
        return writer;
    },
    decode(input, length) {
        const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
        let end = length === undefined ? reader.len : reader.pos + length;
        const message = createBaseDataSourceOffsetRange();
        while (reader.pos < end) {
            const tag = reader.uint32();
            switch (tag >>> 3) {
                case 1:
                    if (tag !== 10) {
                        break;
                    }
                    message.kafkaTopicOffsetRange = DataSourceOffsetRange_KafkaTopicOffsetRange.decode(reader, reader.uint32());
                    continue;
            }
            if ((tag & 7) === 4 || tag === 0) {
                break;
            }
            reader.skipType(tag & 7);
        }
        return message;
    },
    fromJSON(object) {
        return {
            kafkaTopicOffsetRange: isSet(object.kafkaTopicOffsetRange)
                ? DataSourceOffsetRange_KafkaTopicOffsetRange.fromJSON(object.kafkaTopicOffsetRange)
                : undefined,
        };
    },
    toJSON(message) {
        const obj = {};
        if (message.kafkaTopicOffsetRange !== undefined) {
            obj.kafkaTopicOffsetRange = DataSourceOffsetRange_KafkaTopicOffsetRange.toJSON(message.kafkaTopicOffsetRange);
        }
        return obj;
    },
    create(base) {
        return DataSourceOffsetRange.fromPartial(base ?? {});
    },
    fromPartial(object) {
        const message = createBaseDataSourceOffsetRange();
        message.kafkaTopicOffsetRange =
            (object.kafkaTopicOffsetRange !== undefined && object.kafkaTopicOffsetRange !== null)
                ? DataSourceOffsetRange_KafkaTopicOffsetRange.fromPartial(object.kafkaTopicOffsetRange)
                : undefined;
        return message;
    },
};
messageTypeRegistry.set(DataSourceOffsetRange.$type, DataSourceOffsetRange);
function createBaseDataSourceOffsetRange_KafkaTopicOffsetRange() {
    return { topic: "", startOffsetByPartition: {}, endOffsetByPartition: {} };
}
export const DataSourceOffsetRange_KafkaTopicOffsetRange = {
    $type: "reddit.coreplatform.cloudroutines.scheduling.v1.DataSourceOffsetRange.KafkaTopicOffsetRange",
    encode(message, writer = _m0.Writer.create()) {
        if (message.topic !== "") {
            writer.uint32(10).string(message.topic);
        }
        Object.entries(message.startOffsetByPartition).forEach(([key, value]) => {
            DataSourceOffsetRange_KafkaTopicOffsetRange_StartOffsetByPartitionEntry.encode({ key: key, value }, writer.uint32(18).fork()).ldelim();
        });
        Object.entries(message.endOffsetByPartition).forEach(([key, value]) => {
            DataSourceOffsetRange_KafkaTopicOffsetRange_EndOffsetByPartitionEntry.encode({ key: key, value }, writer.uint32(26).fork()).ldelim();
        });
        return writer;
    },
    decode(input, length) {
        const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
        let end = length === undefined ? reader.len : reader.pos + length;
        const message = createBaseDataSourceOffsetRange_KafkaTopicOffsetRange();
        while (reader.pos < end) {
            const tag = reader.uint32();
            switch (tag >>> 3) {
                case 1:
                    if (tag !== 10) {
                        break;
                    }
                    message.topic = reader.string();
                    continue;
                case 2:
                    if (tag !== 18) {
                        break;
                    }
                    const entry2 = DataSourceOffsetRange_KafkaTopicOffsetRange_StartOffsetByPartitionEntry.decode(reader, reader.uint32());
                    if (entry2.value !== undefined) {
                        message.startOffsetByPartition[entry2.key] = entry2.value;
                    }
                    continue;
                case 3:
                    if (tag !== 26) {
                        break;
                    }
                    const entry3 = DataSourceOffsetRange_KafkaTopicOffsetRange_EndOffsetByPartitionEntry.decode(reader, reader.uint32());
                    if (entry3.value !== undefined) {
                        message.endOffsetByPartition[entry3.key] = entry3.value;
                    }
                    continue;
            }
            if ((tag & 7) === 4 || tag === 0) {
                break;
            }
            reader.skipType(tag & 7);
        }
        return message;
    },
    fromJSON(object) {
        return {
            topic: isSet(object.topic) ? globalThis.String(object.topic) : "",
            startOffsetByPartition: isObject(object.startOffsetByPartition)
                ? Object.entries(object.startOffsetByPartition).reduce((acc, [key, value]) => {
                    acc[globalThis.Number(key)] = Number(value);
                    return acc;
                }, {})
                : {},
            endOffsetByPartition: isObject(object.endOffsetByPartition)
                ? Object.entries(object.endOffsetByPartition).reduce((acc, [key, value]) => {
                    acc[globalThis.Number(key)] = Number(value);
                    return acc;
                }, {})
                : {},
        };
    },
    toJSON(message) {
        const obj = {};
        if (message.topic !== "") {
            obj.topic = message.topic;
        }
        if (message.startOffsetByPartition) {
            const entries = Object.entries(message.startOffsetByPartition);
            if (entries.length > 0) {
                obj.startOffsetByPartition = {};
                entries.forEach(([k, v]) => {
                    obj.startOffsetByPartition[k] = Math.round(v);
                });
            }
        }
        if (message.endOffsetByPartition) {
            const entries = Object.entries(message.endOffsetByPartition);
            if (entries.length > 0) {
                obj.endOffsetByPartition = {};
                entries.forEach(([k, v]) => {
                    obj.endOffsetByPartition[k] = Math.round(v);
                });
            }
        }
        return obj;
    },
    create(base) {
        return DataSourceOffsetRange_KafkaTopicOffsetRange.fromPartial(base ?? {});
    },
    fromPartial(object) {
        const message = createBaseDataSourceOffsetRange_KafkaTopicOffsetRange();
        message.topic = object.topic ?? "";
        message.startOffsetByPartition = Object.entries(object.startOffsetByPartition ?? {}).reduce((acc, [key, value]) => {
            if (value !== undefined) {
                acc[globalThis.Number(key)] = globalThis.Number(value);
            }
            return acc;
        }, {});
        message.endOffsetByPartition = Object.entries(object.endOffsetByPartition ?? {}).reduce((acc, [key, value]) => {
            if (value !== undefined) {
                acc[globalThis.Number(key)] = globalThis.Number(value);
            }
            return acc;
        }, {});
        return message;
    },
};
messageTypeRegistry.set(DataSourceOffsetRange_KafkaTopicOffsetRange.$type, DataSourceOffsetRange_KafkaTopicOffsetRange);
function createBaseDataSourceOffsetRange_KafkaTopicOffsetRange_StartOffsetByPartitionEntry() {
    return { key: 0, value: 0 };
}
export const DataSourceOffsetRange_KafkaTopicOffsetRange_StartOffsetByPartitionEntry = {
    $type: "reddit.coreplatform.cloudroutines.scheduling.v1.DataSourceOffsetRange.KafkaTopicOffsetRange.StartOffsetByPartitionEntry",
    encode(message, writer = _m0.Writer.create()) {
        if (message.key !== 0) {
            writer.uint32(8).int32(message.key);
        }
        if (message.value !== 0) {
            writer.uint32(16).int64(message.value);
        }
        return writer;
    },
    decode(input, length) {
        const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
        let end = length === undefined ? reader.len : reader.pos + length;
        const message = createBaseDataSourceOffsetRange_KafkaTopicOffsetRange_StartOffsetByPartitionEntry();
        while (reader.pos < end) {
            const tag = reader.uint32();
            switch (tag >>> 3) {
                case 1:
                    if (tag !== 8) {
                        break;
                    }
                    message.key = reader.int32();
                    continue;
                case 2:
                    if (tag !== 16) {
                        break;
                    }
                    message.value = longToNumber(reader.int64());
                    continue;
            }
            if ((tag & 7) === 4 || tag === 0) {
                break;
            }
            reader.skipType(tag & 7);
        }
        return message;
    },
    fromJSON(object) {
        return {
            key: isSet(object.key) ? globalThis.Number(object.key) : 0,
            value: isSet(object.value) ? globalThis.Number(object.value) : 0,
        };
    },
    toJSON(message) {
        const obj = {};
        if (message.key !== 0) {
            obj.key = Math.round(message.key);
        }
        if (message.value !== 0) {
            obj.value = Math.round(message.value);
        }
        return obj;
    },
    create(base) {
        return DataSourceOffsetRange_KafkaTopicOffsetRange_StartOffsetByPartitionEntry.fromPartial(base ?? {});
    },
    fromPartial(object) {
        const message = createBaseDataSourceOffsetRange_KafkaTopicOffsetRange_StartOffsetByPartitionEntry();
        message.key = object.key ?? 0;
        message.value = object.value ?? 0;
        return message;
    },
};
messageTypeRegistry.set(DataSourceOffsetRange_KafkaTopicOffsetRange_StartOffsetByPartitionEntry.$type, DataSourceOffsetRange_KafkaTopicOffsetRange_StartOffsetByPartitionEntry);
function createBaseDataSourceOffsetRange_KafkaTopicOffsetRange_EndOffsetByPartitionEntry() {
    return { key: 0, value: 0 };
}
export const DataSourceOffsetRange_KafkaTopicOffsetRange_EndOffsetByPartitionEntry = {
    $type: "reddit.coreplatform.cloudroutines.scheduling.v1.DataSourceOffsetRange.KafkaTopicOffsetRange.EndOffsetByPartitionEntry",
    encode(message, writer = _m0.Writer.create()) {
        if (message.key !== 0) {
            writer.uint32(8).int32(message.key);
        }
        if (message.value !== 0) {
            writer.uint32(16).int64(message.value);
        }
        return writer;
    },
    decode(input, length) {
        const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
        let end = length === undefined ? reader.len : reader.pos + length;
        const message = createBaseDataSourceOffsetRange_KafkaTopicOffsetRange_EndOffsetByPartitionEntry();
        while (reader.pos < end) {
            const tag = reader.uint32();
            switch (tag >>> 3) {
                case 1:
                    if (tag !== 8) {
                        break;
                    }
                    message.key = reader.int32();
                    continue;
                case 2:
                    if (tag !== 16) {
                        break;
                    }
                    message.value = longToNumber(reader.int64());
                    continue;
            }
            if ((tag & 7) === 4 || tag === 0) {
                break;
            }
            reader.skipType(tag & 7);
        }
        return message;
    },
    fromJSON(object) {
        return {
            key: isSet(object.key) ? globalThis.Number(object.key) : 0,
            value: isSet(object.value) ? globalThis.Number(object.value) : 0,
        };
    },
    toJSON(message) {
        const obj = {};
        if (message.key !== 0) {
            obj.key = Math.round(message.key);
        }
        if (message.value !== 0) {
            obj.value = Math.round(message.value);
        }
        return obj;
    },
    create(base) {
        return DataSourceOffsetRange_KafkaTopicOffsetRange_EndOffsetByPartitionEntry.fromPartial(base ?? {});
    },
    fromPartial(object) {
        const message = createBaseDataSourceOffsetRange_KafkaTopicOffsetRange_EndOffsetByPartitionEntry();
        message.key = object.key ?? 0;
        message.value = object.value ?? 0;
        return message;
    },
};
messageTypeRegistry.set(DataSourceOffsetRange_KafkaTopicOffsetRange_EndOffsetByPartitionEntry.$type, DataSourceOffsetRange_KafkaTopicOffsetRange_EndOffsetByPartitionEntry);
function longToNumber(long) {
    if (long.gt(globalThis.Number.MAX_SAFE_INTEGER)) {
        throw new globalThis.Error("Value is larger than Number.MAX_SAFE_INTEGER");
    }
    return long.toNumber();
}
if (_m0.util.Long !== Long) {
    _m0.util.Long = Long;
    _m0.configure();
}
function isObject(value) {
    return typeof value === "object" && value !== null;
}
function isSet(value) {
    return value !== null && value !== undefined;
}
